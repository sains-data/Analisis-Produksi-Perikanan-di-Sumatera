
# ğŸ£ Fisheries Production Analysis System â€“ Lampung Province (2019â€“2023)

This project builds a Big Data analytics system to analyze fishery production trends in **Lampung Province, Indonesia**, over a 5-year period (2019â€“2023). The system adopts a **Medallion Architecture (Bronzeâ€“Silverâ€“Gold)** with processing built on top of the **Apache Hadoop ecosystem**, combined with **machine learning** (K-Means & Linear Regression) and **interactive visualization dashboards**.

## ğŸ“¦ System Architecture

- ğŸ”¹ **Bronze Layer**: Stores raw data (CSV, SHP) from KKP, BMKG, and BIG.
- ğŸ”¸ **Silver Layer**: Performs data cleaning and normalization using Apache Spark.
- ğŸŸ¡ **Gold Layer**: Aggregates and analyzes data using ML models and prepares it for dashboards.

### ğŸ”§ Technologies Used

| Component        | Tool/Technology             |
|------------------|-----------------------------|
| Distributed Storage | Hadoop HDFS               |
| Batch Processing  | Apache Spark, Spark MLlib   |
| Query Layer       | Apache Hive                 |
| Workflow Orchestration | Apache Airflow        |
| Visualization     | Apache Superset             |
| Deployment        | Docker & Docker Compose     |
| Monitoring        | Apache Ambari               |

## ğŸ” Key Features

- ğŸ“ˆ Analyze fishery production (volume & value) by region and type
- â˜ï¸ Integrate weather data (temperature, rainfall, humidity) from BMKG
- ğŸ” Cluster regions using K-Means based on environmental and production features
- ğŸ”® Predict production trends using Linear Regression
- ğŸ—ºï¸ Visualize spatial-temporal insights with interactive dashboards
- ğŸ”„ Monitor and automate pipelines with Apache Airflow

## ğŸ—‚ï¸ Project Structure

![alt text](Produksi_ikan_tangkap_laut.csv.png)

```

analisis-produksi-perikanan-di-sumatera/
â”œâ”€â”€ conf/                          # Konfigurasi sistem Hadoop, Hive, dll
â”‚   â”œâ”€â”€ core-site.xml
â”‚   â”œâ”€â”€ hbase-site.xml
â”‚   â”œâ”€â”€ hdfs-site.xml
â”‚   â”œâ”€â”€ hive-site.xml
â”‚   â”œâ”€â”€ log4j.properties
â”‚   â”œâ”€â”€ mapred-site.xml
â”‚   â”œâ”€â”€ masters
â”‚   â”œâ”€â”€ slaves
â”‚   â””â”€â”€ yarn-site.xml
â”‚
â”œâ”€â”€ dataset/                       # Dataset mentah (CSV, TIFF)
â”‚   â”œâ”€â”€ BATNAS_100E-105E_10S-05S_MSL_v1.5.tif
â”‚   â”œâ”€â”€ BATNAS_105E-110E_05S-000_MSL_v1.5.tif
â”‚   â”œâ”€â”€ BATNAS_105E-110E_10S-05S_MSL_v1.5.tif
â”‚   â”œâ”€â”€ Budidaya_Ikan_Hias.csv
â”‚   â”œâ”€â”€ Budidaya_Pembenihan.csv
â”‚   â”œâ”€â”€ Budidaya_Pembesaran.csv
â”‚   â”œâ”€â”€ Data_Curah_Hujan_2019-2023.csv
â”‚   â”œâ”€â”€ Data_Rata-rata_Kelembapan_2019-2023.csv
â”‚   â”œâ”€â”€ Data_Rata-rata_Suhu_2019-2023.csv
â”‚   â”œâ”€â”€ Ikan_Tangkap_Laut.csv
â”‚   â””â”€â”€ Ikan_tangkap_darat.csv
â”‚
â”œâ”€â”€ scripts/                       # Script kontrol cluster
â”‚   â”œâ”€â”€ bootstrap-datanode.sh
â”‚   â”œâ”€â”€ bootstrap-namenode.sh
â”‚   â”œâ”€â”€ start.sh
â”‚   â””â”€â”€ stop.sh
â”‚
â”œâ”€â”€ Dockerfile.airflow             # Dockerfile untuk Airflow
â”œâ”€â”€ Dockerfile.hadoop              # Dockerfile untuk Hadoop (namenode/datanode)
â”œâ”€â”€ Dockerfile.hbase               # Dockerfile untuk HBase
â”œâ”€â”€ Dockerfile.hive                # Dockerfile untuk Hive
â”œâ”€â”€ Dockerfile.spark               # Dockerfile untuk Spark
â”œâ”€â”€ Dockerfile.superset            # Dockerfile untuk Superset
â”œâ”€â”€ Dockerfile.tez                 # Dockerfile untuk Tez (opsional)
â”œâ”€â”€ Dockerfile.zookeeper           # Dockerfile untuk Zookeeper
â”‚
â”œâ”€â”€ README.md                      # Dokumentasi proyek
â”œâ”€â”€ bronze_to_silver.py            # ETL script: tahap Bronze â†’ Silver
â”œâ”€â”€ docker-compose.yml             # Komposisi container
â”œâ”€â”€ mysql-connector-java-8.0.28.jar # JDBC driver MySQL (Hive metastore)
â”œâ”€â”€ spark--org.apache.spark.deploy.master.Master... # (kemungkinan file log/temp)
â”œâ”€â”€ superset-init.sh               # Superset inisialisasi script
â”œâ”€â”€ superset_config.py             # Superset konfigurasi file
â””â”€â”€ zoo.cfg                        # Konfigurasi Zookeeper


````

## ğŸš€ Getting Started

### 1. Clone the Repository
```bash
git clone https://github.com/sains-data/analisis-produksi-perikanan-di-sumatera.git
cd analisis-produksi-perikanan-di-sumatera

````
### 2. Prepare Your Environment

```bash
cp .env.example .env 
```

### 3. Start the Local Cluster with Docker

```bash
docker-compose up -d
```

### 4. Initialize the Cluster

```bash
docker exec -it namenode bash /scripts/init/init-hdfs.sh
docker exec -it hive-server bash /scripts/init/init-hive.sh
docker exec -it hbase-master bash /scripts/init/init-hbase.sh
```
### 5. Upload Raw Datasets to HDFS (Bronze Layer)

```bash
docker exec -it spark-master python3 /scripts/utils/hdfs_utils.py
```

### 6. Run the ETL Pipeline

```bash
docker exec -it spark-master python3 /scripts/etl/bronze_to_silver.py
```
```bash
docker exec -it spark-master python3 /scripts/etl/silver_to_gold.py
```

### 7. Run Data Quality Checks

```bash
docker exec -it spark-master python3 /scripts/etl/data_quality_check.py
```
### 8. Automate with Airflow

```bash
http://localhost:8081
```

### 9. Access Dashboards (Superset)

```bash
http://localhost:8088
```

```bash
Username: admin
Password: admin1233
```

### 10. Monitoring with Prometheus & Grafana

```bash
Prometheus: http://localhost:9090

Grafana: http://localhost:3000
Login: admin / admin
Load the dashboard from:
monitoring/grafana/dashboards/
```

## ğŸ“– **Sample Output**

The project involves:

- Production summary table by district/year

- Fishery productivity cluster map (K-Means)

- Time-series graphs with weather overlay

- Interactive dashboards with geospatial visualizations

---
## **ğŸ“Š Dataset**
- Fishery production (capture & aquaculture) â€“ [KKP]

- Weather data: temperature, rainfall, humidity â€“ [BMKG]

- Geographic data (elevation, depth, zones) â€“ [BIG]

---

**Team Members:**  
- Dinda Joycehana (122140048)
- Elia Meylani Simanjuntak (122450026)
- Presilia (122450081)
- Randa Andriana Putra (122450083)

---

